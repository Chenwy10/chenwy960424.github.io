[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m currently a student in the Robotics institute (Electrical and Computer Engineering department) of University of Toronto,working with Professor Yu Sun. Specifically, I\u0026rsquo;m a part of the 3D vision group which is aimed to develop a Structured light (SL)-based 3D scanner for industrial metrology. Before that, I received the Bachelor degree from Department of Computer Science in Huazhong University of Science and Technology in 2018.\nMy research interests are computer vision, deep learning, and 3D modeling. I am dedicated to improve the level of automation for industrial applications such as defect detection, surface measurement and bin picking. Recently, I\u0026rsquo;m looking for an Ph.D program in 2021, and if you are interested in working with me, please contact me through email.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://chenwy960424.github.io/author/wenyuan-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/wenyuan-chen/","section":"authors","summary":"I\u0026rsquo;m currently a student in the Robotics institute (Electrical and Computer Engineering department) of University of Toronto,working with Professor Yu Sun. Specifically, I\u0026rsquo;m a part of the 3D vision group which is aimed to develop a Structured light (SL)-based 3D scanner for industrial metrology.","tags":null,"title":"Wenyuan Chen","type":"authors"},{"authors":[],"categories":[],"content":"","date":1591326476,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591326476,"objectID":"e3482c0a444eeff89637c2bdc45e8567","permalink":"https://chenwy960424.github.io/project/ta2020/","publishdate":"2020-06-04T23:07:56-04:00","relpermalink":"/project/ta2020/","section":"project","summary":"Winter 2020 Teaching Assistant for Computer Fundamentals","tags":[],"title":"TA","type":"project"},{"authors":["X Liu#","W Chen#","H Madhusudanan","J Ge","C Ru","Y Sun"],"categories":[],"content":"","date":1588204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588204800,"objectID":"ec4c841858ea4401e6abe75a37752c1a","permalink":"https://chenwy960424.github.io/publication/txt_tii-20-0587/","publishdate":"2020-06-04T22:45:25-04:00","relpermalink":"/publication/txt_tii-20-0587/","section":"publication","summary":"Three-dimensional structured light (SL) measurement of highly reﬂective surface is a challenge faced in industrial metrology. The high dynamic range (HDR) technique provides a solution by fusing images under multiple exposures; however, the process is highly time-consuming. This paper reports a new SL-based method to measure parts with highly reﬂective surfaces from only a single exposure. A new quantitative metric is deﬁned to optimally select camera exposure for capturing input single-exposure images. Different from existing image gradient or entropy-based metrics, the new metric incorporates both intensity modulation and overexposure. A skip pyramid context aggregation network (SP-CAN) is proposed to enhance the single exposure-captured images. Compared with existing image enhancement methods, SP-CAN effectively preserves detailed encoded phase information near edges and corners during enhancement. Experiments with various industrial parts demonstrated that the average time cost of the proposed method was 0.6 second, which was only one tenth of the HDR method (ten exposures), and the two methods achieved similar coverage rates (97.6%vs.98.0%)andmeasurementaccuracy(0.040mmvs.0.038 mm).","tags":[],"title":"Optical Measurement of Highly Reflective Surfaces from a Single Exposure","type":"publication"},{"authors":["H Madhusudanan#","X Liu#","W Chen","D Li","L Du","J Li","J Ge and Y Sun"],"categories":[],"content":"","date":1578096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578096000,"objectID":"743189324f028bf498e8d833323e4486","permalink":"https://chenwy960424.github.io/publication/icra2020/","publishdate":"2020-05-04T22:34:48-04:00","relpermalink":"/publication/icra2020/","section":"publication","summary":"A 3D measurement system consisting of a 3D scanner and an industrial robot (eye-in-hand) is commonly used to scan large object under test (OUT) from multiple ﬁeldof-views (FOVs) for complete measurement. A data stitching process is required to align multiple FOVs into a single coordinate system. Marker-free stitching assisted by robot’s accurate positioning becomes increasingly attractive since it bypasses the cumbersome traditional ﬁducial marker-based method. Most existing methods directly use initial Denavit-Hartenberg (DH) parameters and hand-eye calibration to calculate the transformations between multiple FOVs. Since accuracy of DH parameters deteriorates over time, such methods suffer from high stitching errors (e.g., 0.2 mm) in long-term routine industrial use. This paper reports a new robot-scanner calibration approach to realize such measurement with low data stitching errors. During long-term continuous measurement, the robot periodically moves towards a 2D standard calibration board to optimize kinematic model’s parameters to maintain a low stitching error. This capability is enabled by several techniques including virtual arm-based robot-scanner kinematic model, trajectory-based robot-world transformation calculation, nonlinear optimization. Experimental results demonstrated a low data stitching error (","tags":[],"title":"Automated Eye-In-Hand Robot-3D Scanner Calibration for Low Stitching Errors","type":"publication"}]